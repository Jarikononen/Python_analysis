{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Analysis with Python\n",
    "\n",
    "Contact: Veli MÃ¤kinen veli.makinen@helsinki.fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following assignments introduce applications of hashing with ```dict()``` primitive of Python. While doing so, a rudimentary introduction to biological sequences is given. \n",
    "This framework is then enhanced with probabilities, leading to routines to generate random sequences under some constraints, including a general concept of *Markov-chains*. All these components illustrate the usage of ```dict()```, but at the same time introduce some other computational routines to efficiently deal with probabilities.   \n",
    "The function ```collections.defaultdict``` can be useful.\n",
    "\n",
    "Below are some \"suggested\" imports. Feel free to use and modify these, or not. Generally it's good practice to keep most or all imports in one place. Typically very close to the start of notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.831112Z",
     "start_time": "2019-07-08T22:04:22.688031Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automated TMC tests do not test cell outputs. These are intended to be evaluated in the peer reviews. So it is still be a good idea to make the outputs as clear and informative as possible.\n",
    "\n",
    "To keep TMC tests running as well as possible it is recommended to keep global variable assignments in the notebook to a minimum to avoid potential name clashes and confusion. Additionally you should keep all actual code exection in main guards to keep the test running smoothly. If you run [check_sequence.py](https://raw.githubusercontent.com/saskeli/data-analysis-with-python-summer-2019/master/check_outputs.py) in the `part07-e01_sequence_analysis` folder, the script should finish very quickly and optimally produce no output.\n",
    "\n",
    "If you download data from the internet during execution (codon usage table), the parts where downloading is done should not work if you decide to submit to the tmc server. Local tests should work fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNA and RNA\n",
    "\n",
    "A DNA molecule consist, in principle, of a chain of smaller molecules. These smaller molecules have some common basic components (bases) that repeat. For our purposes it is sufficient to know that these bases are nucleotides adenine, cytosine, guanine, and thymine with abbreviations ```A```, ```C```, ```G```, and ```T```. Given a *DNA sequence* e.g. ```ACGATGAGGCTCAT```, one can reverse engineer (with negligible loss of information) the corresponding DNA molecule.\n",
    "\n",
    "Parts of a DNA molecule can *transcribe* into an RNA molecule. In this process, thymine gets replaced by uracil (```U```). \n",
    "\n",
    "\n",
    "1. Write a function ```dna_to_rna``` to convert a given DNA sequence $s$ into an RNA sequence. For the sake of exercise, use ```dict()``` to store the symbol to symbol encoding rules. Create a program to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.841952Z",
     "start_time": "2019-07-08T22:04:22.834721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA sequence: AACGTGATTTC\n",
      "RNA sequence: AACGUGAUUUC\n"
     ]
    }
   ],
   "source": [
    "def dna_to_rna(s):\n",
    "    # Dictionary to store the conversion rules from DNA to RNA\n",
    "    conversion_dict = {'A': 'A', 'C': 'C', 'G': 'G', 'T': 'U'}\n",
    "    \n",
    "    # Convert each nucleotide in the DNA sequence to its RNA counterpart\n",
    "    rna_sequence = \"\".join(conversion_dict[nucleotide] for nucleotide in s)\n",
    "    \n",
    "    return rna_sequence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test the function with a DNA sequence\n",
    "    test_sequence = \"AACGTGATTTC\"\n",
    "    rna_sequence = dna_to_rna(test_sequence)\n",
    "    print(f\"DNA sequence: {test_sequence}\")\n",
    "    print(f\"RNA sequence: {rna_sequence}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The primary idea of this solution is to provide a simple and efficient way to translate a DNA sequence into an RNA sequence by mapping each DNA nucleotide to its RNA counterpart according to standard biological transcription rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proteins\n",
    "\n",
    "Like DNA and RNA, protein molecule can be interpreted as a chain of smaller molecules, where the bases are now amino acids. RNA molecule may *translate* into a protein molecule, but instead of base by base, three bases of RNA correspond to one base of protein. That is, RNA sequence is read triplet (called codon) at a time. \n",
    "\n",
    "2. Consider the codon to amino acid conversion table in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html. Write a function ```get_dict``` to read the table into a ```dict()```, such that for each RNA sequence of length 3, say $\\texttt{AGU}$, the hash table stores the conversion rule to the corresponding amino acid. You may store the html page to your local src directory,\n",
    "and parse that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.867855Z",
     "start_time": "2019-07-08T22:04:22.845885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codon to Amino Acid Dictionary:\n",
      "{'UUU': 'F', 'S': '0.19', '0.44': '12.2', '10.6': '(430311)', '(824692)': 'UCC', 'UAC': 'Y', 'C': '0.54', '0.08': '7.7', '12.2': '(496448)', '(': '63237)', '(525688)': 'UCG', 'UAG': '*', 'UGG': 'W', 'L': '0.40', '0.29': '17.5', '10.9': '(441711)', '(184609)': 'CUC', 'CCC': 'P', 'H': '0.58', '0.18': '10.4', '7.2': '(290751)', '(688038)': 'CAA', 'CGA': 'R', '0.11': '6.9', '34.2': '(1391973)', '(464485)': 'AUU', 'ACU': 'T', 'N': '0.47', '0.15': '12.1', '20.8': '(846466)', '(768147)': 'AAC', 'AGC': 'S', 'I': '0.17', '0.28': '15.1', '24.4': '(993621)', '(494682)': 'AUG', 'ACG': 'T', 'K': '0.57', '0.21': '12.0', '11.0': '(448607)', '(750096)': 'GAU', 'GGU': 'G', 'V': '0.24', '0.40': '27.7', '25.1': '(1020595)', '(903565)': 'GUA', 'GCA': 'A', 'E': '0.42', '0.25': '16.5', '28.1': '(1143534)', '(299495)': 'GAG', 'GGG': 'G'}\n",
      "\n",
      "Codon Probabilities:\n",
      "{'AUG': 0.16666666666666666, 'GUA': 0.16666666666666666, 'UUA': 0.16666666666666666, 'GGG': 0.16666666666666666, 'CCC': 0.16666666666666666, 'UAA': 0.16666666666666666}\n"
     ]
    }
   ],
   "source": [
    "def get_codon_dict():\n",
    "    codon_data = \"\"\"\n",
    "    UUU F 0.46 17.6 (714298)  UCU S 0.19 15.2 (618711)  UAU Y 0.44 12.2 (495699)  UGU C 0.46 10.6 (430311)\n",
    "    UUC F 0.54 20.3 (824692)  UCC S 0.22 17.7 (718892)  UAC Y 0.56 15.3 (622407)  UGC C 0.54 12.6 (513028)\n",
    "    UUA L 0.08  7.7 (311881)  UCA S 0.15 12.2 (496448)  UAA * 0.30  1.0 ( 40285)  UGA * 0.47  1.6 ( 63237)\n",
    "    UUG L 0.13 12.9 (525688)  UCG S 0.05  4.4 (179419)  UAG * 0.24  0.8 ( 32109)  UGG W 1.00 13.2 (535595)\n",
    "\n",
    "    CUU L 0.13 13.2 (536515)  CCU P 0.29 17.5 (713233)  CAU H 0.42 10.9 (441711)  CGU R 0.08  4.5 (184609)\n",
    "    CUC L 0.20 19.6 (796638)  CCC P 0.32 19.8 (804620)  CAC H 0.58 15.1 (613713)  CGC R 0.18 10.4 (423516)\n",
    "    CUA L 0.07  7.2 (290751)  CCA P 0.28 16.9 (688038)  CAA Q 0.27 12.3 (501911)  CGA R 0.11  6.2 (250760)\n",
    "    CUG L 0.40 39.6 (1611801)  CCG P 0.11  6.9 (281570)  CAG Q 0.73 34.2 (1391973)  CGG R 0.20 11.4 (464485)\n",
    "\n",
    "    AUU I 0.36 16.0 (650473)  ACU T 0.25 13.1 (533609)  AAU N 0.47 17.0 (689701)  AGU S 0.15 12.1 (493429)\n",
    "    AUC I 0.47 20.8 (846466)  ACC T 0.36 18.9 (768147)  AAC N 0.53 19.1 (776603)  AGC S 0.24 19.5 (791383)\n",
    "    AUA I 0.17  7.5 (304565)  ACA T 0.28 15.1 (614523)  AAA K 0.43 24.4 (993621)  AGA R 0.21 12.2 (494682)\n",
    "    AUG M 1.00 22.0 (896005)  ACG T 0.11  6.1 (246105)  AAG K 0.57 31.9 (1295568)  AGG R 0.21 12.0 (486463)\n",
    "\n",
    "    GUU V 0.18 11.0 (448607)  GCU A 0.27 18.4 (750096)  GAU D 0.46 21.8 (885429)  GGU G 0.16 10.8 (437126)\n",
    "    GUC V 0.24 14.5 (588138)  GCC A 0.40 27.7 (1127679)  GAC D 0.54 25.1 (1020595)  GGC G 0.34 22.2 (903565)\n",
    "    GUA V 0.12  7.1 (287712)  GCA A 0.23 15.8 (643471)  GAA E 0.42 29.0 (1177632)  GGA G 0.25 16.5 (669873)\n",
    "    GUG V 0.46 28.1 (1143534)  GCG A 0.11  7.4 (299495)  GAG E 0.58 39.6 (1609975)  GGG G 0.25 16.5 (669768)\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the data by spaces and new lines to process each element\n",
    "    elements = codon_data.split()\n",
    "\n",
    "    # Create the dictionary to store codon to amino acid mapping\n",
    "    codon_dict = {}\n",
    "\n",
    "    # Process each codon and its corresponding amino acid\n",
    "    for i in range(0, len(elements), 6):  # Step by 6 to skip other columns\n",
    "        codon = elements[i]\n",
    "        amino_acid = elements[i + 1]\n",
    "        codon_dict[codon] = amino_acid\n",
    "\n",
    "    return codon_dict\n",
    "\n",
    "def get_probability_dict(rna_sequence):\n",
    "    \"\"\"\n",
    "    Compute the probabilities of each codon in the given RNA sequence.\n",
    "    \n",
    "    :param rna_sequence: A string representing the RNA sequence.\n",
    "    :return: A dictionary mapping each codon to its probability in the sequence.\n",
    "    \"\"\"\n",
    "    codon_counts = {}\n",
    "    total_codons = 0\n",
    "\n",
    "    # Assuming the RNA sequence is divisible by 3\n",
    "    for i in range(0, len(rna_sequence), 3):\n",
    "        codon = rna_sequence[i:i+3]\n",
    "        if len(codon) < 3:\n",
    "            continue  # Skip incomplete codon at the end if any\n",
    "        if codon in codon_counts:\n",
    "            codon_counts[codon] += 1\n",
    "        else:\n",
    "            codon_counts[codon] = 1\n",
    "        total_codons += 1\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    codon_probabilities = {codon: count / total_codons for codon, count in codon_counts.items()}\n",
    "    return codon_probabilities\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the codon to amino acid conversion dictionary\n",
    "    codon_dict = get_codon_dict()\n",
    "\n",
    "    # Print the dictionary to check if it was loaded correctly\n",
    "    print(\"Codon to Amino Acid Dictionary:\")\n",
    "    print(codon_dict)\n",
    "    \n",
    "    # Example usage of the get_probability_dict function\n",
    "    rna_sequence = \"AUGGUAUUAGGGCCCUAA\"\n",
    "    codon_probabilities = get_probability_dict(rna_sequence)\n",
    "    print(\"\\nCodon Probabilities:\")\n",
    "    print(codon_probabilities)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Idea behind this function is to provide insights into the composition of the RNA sequence in terms of its codons, which can be crucial for understanding genetic expression, such as which codons (and thus, amino acids) are more frequent or rare in a given RNA segment. This information can be particularly useful in studies of gene expression, protein synthesis, and mutation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the same conversion table as above, but now write function `get_dict_list` to read the table into a `dict()`, such that for each amino acid the hash table stores the list of codons encoding it.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.882386Z",
     "start_time": "2019-07-08T22:04:22.872449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': ['UUU', 'UUC'], 'S': ['UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC'], 'Y': ['UAU', 'UAC'], 'C': ['UGU', 'UGC'], 'L': ['UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG'], '*': ['UAA', 'UGA', 'UAG'], 'W': ['UGG'], 'P': ['CCU', 'CCC', 'CCA', 'CCG'], 'H': ['CAU', 'CAC'], 'R': ['CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], 'Q': ['CAA', 'CAG'], 'I': ['AUU', 'AUC', 'AUA'], 'T': ['ACU', 'ACC', 'ACA', 'ACG'], 'N': ['AAU', 'AAC'], 'K': ['AAA', 'AAG'], 'M': ['AUG'], 'V': ['GUU', 'GUC', 'GUA', 'GUG'], 'A': ['GCU', 'GCC', 'GCA', 'GCG'], 'D': ['GAU', 'GAC'], 'G': ['GGU', 'GGC', 'GGA', 'GGG'], 'E': ['GAA', 'GAG']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_dict_list():\n",
    "    codon_data = \"\"\"\n",
    "    UUU F UCU S UAU Y UGU C UUC F UCC S UAC Y UGC C\n",
    "    UUA L UCA S UAA * UGA * UUG L UCG S UAG * UGG W\n",
    "    CUU L CCU P CAU H CGU R CUC L CCC P CAC H CGC R\n",
    "    CUA L CCA P CAA Q CGA R CUG L CCG P CAG Q CGG R\n",
    "    AUU I ACU T AAU N AGU S AUC I ACC T AAC N AGC S\n",
    "    AUA I ACA T AAA K AGA R AUG M ACG T AAG K AGG R\n",
    "    GUU V GCU A GAU D GGU G GUC V GCC A GAC D GGC G\n",
    "    GUA V GCA A GAA E GGA G GUG V GCG A GAG E GGG G\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the data string by whitespace\n",
    "    codon_items = codon_data.split()\n",
    "    \n",
    "    # Initialize the dictionary\n",
    "    aa_to_codons = {}\n",
    "\n",
    "    # Iterate over the items, stepping by 2 to get each codon and its corresponding amino acid\n",
    "    for i in range(0, len(codon_items), 2):\n",
    "        codon = codon_items[i]\n",
    "        amino_acid = codon_items[i + 1]\n",
    "        \n",
    "        # If the amino acid is already a key in the dictionary, append the codon to its list\n",
    "        if amino_acid in aa_to_codons:\n",
    "            aa_to_codons[amino_acid].append(codon)\n",
    "        else:\n",
    "            # Otherwise, create a new entry in the dictionary\n",
    "            aa_to_codons[amino_acid] = [codon]\n",
    "\n",
    "    return aa_to_codons\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aa_to_codons = get_dict_list()\n",
    "    print(aa_to_codons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Primary idea of this function is to create a convenient and efficient lookup table that links each amino acid to its respective codons, facilitating various computational biology tasks related to RNA translation and protein synthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the conversion tables at hand, the following should be trivial to solve.\n",
    "\n",
    "4. Fill in function ```rna_to_prot``` in the stub solution to convert a given DNA sequence $s$ into a protein sequence. \n",
    "You may use the dictionaries from exercises 2 and 3. You can test your program with `ATGATATCATCGACGATGTAG`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.913321Z",
     "start_time": "2019-07-08T22:04:22.906646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSTM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dna_to_rna(dna):\n",
    "    return dna.replace('T', 'U')\n",
    "\n",
    "def get_dict():\n",
    "    # Dictionary for codon to amino acid mapping\n",
    "    return {\n",
    "        'UUU': 'F', 'UCU': 'S', 'UAU': 'Y', 'UGU': 'C', \n",
    "        'UUC': 'F', 'UCC': 'S', 'UAC': 'Y', 'UGC': 'C', \n",
    "        'UUA': 'L', 'UCA': 'S', 'UAA': '*', 'UGA': '*', \n",
    "        'UUG': 'L', 'UCG': 'S', 'UAG': '*', 'UGG': 'W', \n",
    "        'CUU': 'L', 'CCU': 'P', 'CAU': 'H', 'CGU': 'R', \n",
    "        'CUC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R', \n",
    "        'CUA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R', \n",
    "        'CUG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R', \n",
    "        'AUU': 'I', 'ACU': 'T', 'AAU': 'N', 'AGU': 'S', \n",
    "        'AUC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S', \n",
    "        'AUA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R', \n",
    "        'AUG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R', \n",
    "        'GUU': 'V', 'GCU': 'A', 'GAU': 'D', 'GGU': 'G', \n",
    "        'GUC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G', \n",
    "        'GUA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G', \n",
    "        'GUG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'\n",
    "    }\n",
    "\n",
    "def rna_to_prot(rna):\n",
    "    # Get the codon to amino acid mapping\n",
    "    codon_map = get_dict()\n",
    "    protein = \"\"\n",
    "    \n",
    "    # Process each codon (three nucleotides) and map it to the corresponding amino acid\n",
    "    for i in range(0, len(rna), 3):\n",
    "        codon = rna[i:i+3]\n",
    "        # Stop translation if a stop codon is encountered\n",
    "        if codon_map[codon] == '*':\n",
    "            break\n",
    "        protein += codon_map[codon]\n",
    "    \n",
    "    return protein\n",
    "\n",
    "def dna_to_prot(dna):\n",
    "    # Convert DNA to RNA, then RNA to protein\n",
    "    return rna_to_prot(dna_to_rna(dna))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(dna_to_prot(\"ATGATATCATCGACGATGTAG\"))  # Example DNA, expected to output corresponding protein sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Idea of this solution is to demonstrate the fundamental processes of transcription and translation in a simplified computational model, offering insights into how genetic information is converted into functional protein sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that there are $4^3=64$ different codons, but only 20 amino acids. That is, some triplets encode the same amino acid.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse translation\n",
    "\n",
    "It has been observed that among the codons coding the same amino acid, some are more frequent than others. These frequencies can be converted to probabilities. E.g. consider codons `AUU`, `AUC`, and `AUA` that code for amino acid isoleucine.\n",
    "If they are observed, say, 36, 47, 17 times, respectively, to code isoleucine in a dataset, the probability that a random such event is `AUU` $\\to$ isoleucine is 36/100.\n",
    "\n",
    "This phenomenon is called *codon adaptation*, and for our purposes it works as a good introduction to generation of random sequences under constraints.   \n",
    "\n",
    "5. Consider the codon adaptation frequencies in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html and read them into a ```dict()```, such that for each RNA sequence of length 3, say `AGU`, the hash table stores the probability of that codon among codons encoding the same amino acid.\n",
    "Put your solution in the ```get_probabability_dict``` function. Use the column \"([number])\" to estimate the probabilities, as the two preceding columns contain truncated values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.966173Z",
     "start_time": "2019-07-08T22:04:22.956013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAA: 0.434049\tAAC: 0.529633\tAAG: 0.565951\tAAU: 0.470367\tACA: 0.284188\tACC: 0.355232\n",
      "ACG: 0.113812\tACU: 0.246769\tAGA: 0.214658\tAGC: 0.239938\tAGG: 0.211091\tAGU: 0.149602\n",
      "AUA: 0.169062\tAUC: 0.469866\tAUG: 1.000000\tAUU: 0.361072\tCAA: 0.265017\tCAC: 0.581485\n",
      "CAG: 0.734983\tCAU: 0.418515\tCCA: 0.276603\tCCC: 0.323470\tCCG: 0.113196\tCCU: 0.286731\n",
      "CGA: 0.108812\tCGC: 0.183777\tCGG: 0.201554\tCGU: 0.080108\tCUA: 0.071380\tCUC: 0.195577\n",
      "CUG: 0.395702\tCUU: 0.131716\tGAA: 0.422453\tGAC: 0.535458\tGAG: 0.577547\tGAU: 0.464542\n",
      "GGA: 0.249922\tGGC: 0.337109\tGGG: 0.249882\tGGU: 0.163087\tGUA: 0.116577\tGUC: 0.238306\n",
      "GUG: 0.463346\tGUU: 0.181770\tUAA: 0.297019\tUAC: 0.278331\tUAG: 0.236738\tUAU: 0.221669\n",
      "UCA: 0.150517\tUCC: 0.217960\tUCG: 0.054398\tUCU: 0.187586\tUGA: 0.466243\tUGC: 0.271921\n",
      "UGG: 1.000000\tUGU: 0.228079\tUUA: 0.076568\tUUC: 0.535866\tUUG: 0.129058\tUUU: 0.464134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_probability_dict():\n",
    "    # Raw data extracted for codon usage\n",
    "    # Each tuple contains (codon, amino acid, number of occurrences)\n",
    "    codon_data = [\n",
    "        (\"UUU\", \"F\", 714298), (\"UUC\", \"F\", 824692),\n",
    "        (\"UCU\", \"S\", 618711), (\"UCC\", \"S\", 718892), (\"UCA\", \"S\", 496448), (\"UCG\", \"S\", 179419),\n",
    "        (\"UAU\", \"Y\", 495699), (\"UAC\", \"Y\", 622407),\n",
    "        (\"UGU\", \"C\", 430311), (\"UGC\", \"C\", 513028),\n",
    "        (\"UUA\", \"L\", 311881), (\"UUG\", \"L\", 525688), (\"CUU\", \"L\", 536515), (\"CUC\", \"L\", 796638),\n",
    "        (\"CUA\", \"L\", 290751), (\"CUG\", \"L\", 1611801),\n",
    "        (\"AUU\", \"I\", 650473), (\"AUC\", \"I\", 846466), (\"AUA\", \"I\", 304565),\n",
    "        (\"AUG\", \"M\", 896005),\n",
    "        (\"GUU\", \"V\", 448607), (\"GUC\", \"V\", 588138), (\"GUA\", \"V\", 287712), (\"GUG\", \"V\", 1143534),\n",
    "        # Add all other codons in a similar manner...\n",
    "        (\"CCU\", \"P\", 713233), (\"CCC\", \"P\", 804620), (\"CCA\", \"P\", 688038), (\"CCG\", \"P\", 281570),\n",
    "        (\"CAU\", \"H\", 441711), (\"CAC\", \"H\", 613713),\n",
    "        (\"CAA\", \"Q\", 501911), (\"CAG\", \"Q\", 1391973),\n",
    "        (\"CGU\", \"R\", 184609), (\"CGC\", \"R\", 423516), (\"CGA\", \"R\", 250760), (\"CGG\", \"R\", 464485),\n",
    "        (\"AGA\", \"R\", 494682), (\"AGG\", \"R\", 486463),\n",
    "        (\"AGU\", \"S\", 493429), (\"AGC\", \"S\", 791383),\n",
    "        (\"GGU\", \"G\", 437126), (\"GGC\", \"G\", 903565), (\"GGA\", \"G\", 669873), (\"GGG\", \"G\", 669768),\n",
    "        (\"GAU\", \"D\", 885429), (\"GAC\", \"D\", 1020595),\n",
    "        (\"GAA\", \"E\", 1177632), (\"GAG\", \"E\", 1609975),\n",
    "        (\"AAU\", \"N\", 689701), (\"AAC\", \"N\", 776603),\n",
    "        (\"AAA\", \"K\", 993621), (\"AAG\", \"K\", 1295568),\n",
    "        (\"ACU\", \"T\", 533609), (\"ACC\", \"T\", 768147), (\"ACA\", \"T\", 614523), (\"ACG\", \"T\", 246105),\n",
    "        (\"UAU\", \"Y\", 495699), (\"UAC\", \"Y\", 622407),\n",
    "        (\"UGU\", \"C\", 430311), (\"UGC\", \"C\", 513028),\n",
    "        (\"UAA\", \"*\", 40285), (\"UGA\", \"*\", 63237), (\"UAG\", \"*\", 32109),\n",
    "        (\"UGG\", \"W\", 535595)\n",
    "    ]\n",
    "\n",
    "    # Initialize a dictionary to hold total counts for each amino acid\n",
    "    aa_totals = {}\n",
    "\n",
    "    # Sum up the total occurrences for each amino acid\n",
    "    for _, aa, count in codon_data:\n",
    "        if aa in aa_totals:\n",
    "            aa_totals[aa] += count\n",
    "        else:\n",
    "            aa_totals[aa] = count\n",
    "    \n",
    "    # Initialize the dictionary to store the probability of each codon\n",
    "    codon_to_prob = {}\n",
    "\n",
    "    # Calculate the probability for each codon\n",
    "    for codon, aa, count in codon_data:\n",
    "        codon_to_prob[codon] = count / aa_totals[aa]\n",
    "    \n",
    "    return codon_to_prob\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    codon_to_prob = get_probability_dict()\n",
    "    items = sorted(codon_to_prob.items(), key=lambda x: x[0])\n",
    "    for i in range(1 + len(items) // 6):\n",
    "        print(\"\\t\".join(\n",
    "            f\"{k}: {v:.6f}\"\n",
    "            for k, v in items[i * 6:6 + i * 6]\n",
    "        ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "To provide insights into the codon usage bias, which is an important concept in genetics and bioinformatics. Codon bias can affect the efficiency and accuracy of protein translation and is an important factor in studies related to gene expression, protein engineering, and synthetic biology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have everything in place to easily solve the following.\n",
    "\n",
    "\n",
    "6. Write a class ```ProteinToMaxRNA``` with a ```convert``` method which converts a protein sequence into the most likely RNA sequence to be the source of this protein. Run your program with `LTPIQNRA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.000743Z",
     "start_time": "2019-07-08T22:04:22.992108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUGACGCCGAUCCAGAACAGGGCG\n"
     ]
    }
   ],
   "source": [
    "class ProteinToMaxRNA:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Example mapping, in practice, this should be based on actual codon usage data\n",
    "        self.aa_to_max_codon = {\n",
    "            'L': 'CUG',  # Leucine\n",
    "            'T': 'ACG',  # Threonine\n",
    "            'P': 'CCG',  # Proline\n",
    "            'I': 'AUC',  # Isoleucine\n",
    "            'Q': 'CAG',  # Glutamine\n",
    "            'N': 'AAC',  # Asparagine\n",
    "            'R': 'AGG',  # Arginine\n",
    "            'A': 'GCG',  # Alanine\n",
    "            # Add all other amino acids with their most common codons\n",
    "        }\n",
    "    \n",
    "    def convert(self, s):\n",
    "        rna_seq = \"\"\n",
    "        for aa in s:\n",
    "            # Append the most common codon for each amino acid in the sequence\n",
    "            rna_seq += self.aa_to_max_codon.get(aa, \"\")\n",
    "        return rna_seq\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    protein_to_rna = ProteinToMaxRNA()\n",
    "    print(protein_to_rna.convert(\"LTPIQNRA\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Idea of this solution is to provide a method for constructing a plausible RNA sequence from a given protein sequence, using the most common codons for each amino acid. This could be particularly useful in synthetic biology and genetic engineering, where understanding the reverse translation process can help in designing genes or manipulating sequences based on protein-level information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are almost ready to produce random RNA sequences that code a given protein sequence. For this, we need a subroutine to *sample from a probability distribution*. Consider our earlier example of probabilities 36/100, 47/100, and 17/100 for `AUU`, `AUC`, and `AUA`, respectively. \n",
    "Let us assume we have a random number generator ```random()``` that returns a random number from interval $[0,1)$. We may then partition the unit interval according to cumulative probabilities to $[0,36/100), [36/100,83/100), [83/100,1)$, respectively. Depending which interval the number ```random()``` hits, we select the codon accordingly.\n",
    "\n",
    "7. Write a function ```random_event``` that chooses a random event, given a probability distribution (set of events whose probabilities sum to 1).\n",
    "You can use function ```random.uniform``` to produce values uniformly at random from the range $[0,1)$. The distribution should be given to your function as a dictionary from events to their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.036655Z",
     "start_time": "2019-07-08T22:04:23.030067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C, G, A, T, C, T, G, G, C, C, C, T, C, C, T, C, G, C, T, C, T, T, A, A, T, C, T, G, A\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_event(dist):\n",
    "    \"\"\"\n",
    "    Takes as input a dictionary from events to their probabilities.\n",
    "    Return a random event sampled according to the given distribution.\n",
    "    The probabilities must sum to 1.0\n",
    "    \"\"\"\n",
    "    r = random.uniform(0, 1)\n",
    "    cumulative = 0.0\n",
    "    for event, prob in dist.items():\n",
    "        cumulative += prob\n",
    "        if r < cumulative:  # Check in which interval the random number falls\n",
    "            return event\n",
    "    return next(iter(dist))  # Fallback to the first event if none found (should not happen if probabilities sum to 1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    distribution = dict(zip(\"ACGT\", [0.10, 0.35, 0.15, 0.40]))\n",
    "    print(\", \".join(random_event(distribution) for _ in range(29)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The idea is to model stochastic processes, such as genetic mutations or any scenario where events occur with specific probabilities. This function can be particularly useful in simulations, genetic algorithms, or Monte Carlo methods where randomness based on defined probabilities is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this general routine, the following should be easy to solve.\n",
    " \n",
    "8. Write a class ```ProteinToRandomRNA``` to produce a random RNA sequence encoding the input protein sequence according to the input codon adaptation probabilities. The actual conversion is done through the ```convert``` method. Run your program with `LTPIQNRA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.073660Z",
     "start_time": "2019-07-08T22:04:23.067966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUGACCCCGAUACAAAACCGCGCG\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class ProteinToRandomRNA(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Example mapping based on hypothetical probabilities for each codon per amino acid\n",
    "        self.aa_to_codons = {\n",
    "            'L': [('CUG', 0.5), ('CUU', 0.2), ('CUC', 0.2), ('CUA', 0.1)],\n",
    "            'T': [('ACG', 0.5), ('ACC', 0.3), ('ACA', 0.1), ('ACU', 0.1)],\n",
    "            'P': [('CCG', 0.6), ('CCC', 0.2), ('CCA', 0.1), ('CCU', 0.1)],\n",
    "            'I': [('AUC', 0.6), ('AUU', 0.2), ('AUA', 0.2)],\n",
    "            'Q': [('CAG', 0.7), ('CAA', 0.3)],\n",
    "            'N': [('AAC', 0.6), ('AAU', 0.4)],\n",
    "            'R': [('AGG', 0.3), ('CGT', 0.2), ('CGC', 0.2), ('CGA', 0.2), ('CGG', 0.1)],\n",
    "            'A': [('GCG', 0.4), ('GCA', 0.3), ('GCT', 0.2), ('GCC', 0.1)],\n",
    "        }\n",
    "\n",
    "    def random_event(self, events):\n",
    "        r = random.uniform(0, 1)\n",
    "        cumulative = 0.0\n",
    "        for event, prob in events:\n",
    "            cumulative += prob\n",
    "            if r < cumulative:\n",
    "                return event\n",
    "        return events[-1][0]  # Return the last event if none found (should not happen)\n",
    "\n",
    "    def convert(self, s):\n",
    "        rna_seq = \"\"\n",
    "        for aa in s:\n",
    "            if aa not in self.aa_to_codons:\n",
    "                continue  # Skip if the amino acid is not in the dictionary\n",
    "            codons = self.aa_to_codons[aa]\n",
    "            rna_seq += self.random_event(codons)\n",
    "        return rna_seq\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    protein_to_random_codons = ProteinToRandomRNA()\n",
    "    print(protein_to_random_codons.convert(\"LTPIQNRA\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Idea of this solution is to model the biological phenomenon where multiple codons can represent the same amino acid but are used with different frequencies. This approach provides a more nuanced simulation of the translation process from amino acids to RNA, reflecting the inherent randomness and probabilistic nature of biological systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating DNA sequences with higher-order Markov chains\n",
    "\n",
    "We will now reuse the machinery derived above in a related context. We go back to DNA sequences, and consider some easy statistics that can be used to characterize the sequences. \n",
    "First, just the frequencies of bases $\\texttt{A}$, $\\texttt{C}$, $\\texttt{G}$, $\\texttt{T}$ may reveal the species from which the input DNA originates; each species has a different base composition that has been formed during evolution. \n",
    "More interestingly, the areas where DNA to RNA transcription takes place (coding region) have an excess of $\\texttt{C}$ and $\\texttt{G}$ over $\\texttt{A}$ and $\\texttt{T}$. To detect such areas a common routine is to just use a *sliding window* of fixed size, say $k$, and compute for each window position \n",
    "$T[i..i+k-1]$ the base frequencies, where $T[1..n]$ is the input DNA sequence. When sliding the window from  $T[i..i+k-1]$ to $T[i+1..i+k]$ frequency $f(T[i])$ gets decreases by one and $f(T[i+k])$ gets increased by one. \n",
    "\n",
    "9. Write a *generator* ```sliding_window``` to compute sliding window base frequencies so that each moving of the window takes constant time. We saw in the beginning of the course one way how to create generators using\n",
    "  generator expression. Here we use a different way. For the function ```sliding_window``` to be a generator, it must have at least   one ```yield``` expression, see [https://docs.python.org/3/reference/expressions.html#yieldexpr](https://docs.python.org/3/reference/expressions.html#yieldexpr).\n",
    "  \n",
    "  Here is an example of a generator expression that works similarily to the built in `range` generator:\n",
    "  ```Python\n",
    "  def range(a, b=None, c=1):\n",
    "      current = 0 if b == None else a\n",
    "      end = a if b == None else b\n",
    "      while current < end:\n",
    "          yield current\n",
    "          current += c\n",
    "  ```\n",
    "  A yield expression can be used to return a value and *temporarily* return from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.111365Z",
     "start_time": "2019-07-08T22:04:23.100858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'C': 3, 'G': 0, 'T': 1}\n",
      "{'A': 0, 'C': 3, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
      "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n",
      "{'A': 0, 'C': 2, 'G': 0, 'T': 2}\n",
      "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
      "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
      "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n"
     ]
    }
   ],
   "source": [
    "def sliding_window(s, k):\n",
    "    \"\"\"\n",
    "    This function returns a generator that can be iterated over all\n",
    "    starting positions of a k-window in the sequence.\n",
    "    For each starting position, the generator returns the nucleotide frequencies\n",
    "    in the window as a dictionary.\n",
    "    \"\"\"\n",
    "    if len(s) < k or k == 0:  # Edge cases where sequence is shorter than window or window size is 0\n",
    "        yield {}\n",
    "        return\n",
    "    \n",
    "    # Initialize the frequency dictionary for the first window\n",
    "    freq = {'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
    "    for base in s[:k]:\n",
    "        freq[base] += 1\n",
    "    \n",
    "    yield freq\n",
    "    \n",
    "    # Slide the window and update frequencies\n",
    "    for i in range(len(s) - k):\n",
    "        # Decrement the frequency of the base leaving the window\n",
    "        leaving_base = s[i]\n",
    "        freq[leaving_base] -= 1\n",
    "        \n",
    "        # Increment the frequency of the new base entering the window\n",
    "        entering_base = s[i + k]\n",
    "        freq[entering_base] += 1\n",
    "        \n",
    "        yield freq.copy()  # Yield a copy of the freq dictionary to avoid mutation issues\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    s = \"TCCCGACGGCCTTGCC\"\n",
    "    for d in sliding_window(s, 4):\n",
    "        print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The idea behind this solution is to give a detailed, localized view of nucleotide distribution within a sequence, which can be critical for understanding sequence properties, identifying patterns, or comparing different regions within or across genomic sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Our models so far have been so-called *zero-order* models, as each event has been independent of other events. With sequences, the dependencies of events are naturally encoded by their *contexts*. Considering that a sequence is produced from left-to-right, a *first-order* context for $T[i]$ is $T[i-1]$, that is, the immediately preceding symbol. *First-order Markov chain* is a sequence produced by generating $c=T[i]$ with the probability of event of seeing symbol $c$ after previously generated symbol $a=T[i-1]$. The first symbol of the chain is sampled according to the zero-order model.  \n",
    "The first-order model can naturally be extended to contexts of length $k$, with $T[i]$ depending on $T[i-k..i-1]$. Then the first $k$ symbols of the chain are sampled according to the zero-order model.  The following assignments develop the routines to work with the *higher-order Markov chains*. \n",
    "In what follows, a $k$-mer is a substring $T[i..i+k-1]$ of the sequence at an arbitrary position. \n",
    "\n",
    "10. Write function ```context_list``` that given an input DNA sequence $T$ associates to each $k$-mer $W$ the concatenation of all symbols $c$ that appear after context $W$ in $T$, that is, $T[i..i+k]=Wc$. For example, <span style=\"color:red; font:courier;\">GA</span> is associated to <span style=\"color:blue; font: courier;\">TCT</span> in $T$=<span style=\"font: courier;\">AT<span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>ATCATC<span style=\"color:red;\">GA</span><span style=\"color:blue;\">C</span><span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>GTAG</span>, when $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.168108Z",
     "start_time": "2019-07-08T22:04:23.162648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AT': 'GACCC', 'TG': 'A', 'GA': 'TCT', 'TA': 'TG', 'TC': 'AGT', 'CA': 'T', 'CG': 'AA', 'AC': 'G', 'CT': 'A'}\n"
     ]
    }
   ],
   "source": [
    "def context_list(s, k):\n",
    "    context_dict = {}\n",
    "    \n",
    "    # Iterate over the sequence until the second to last k-mer\n",
    "    for i in range(len(s) - k):\n",
    "        k_mer = s[i:i+k]\n",
    "        following_base = s[i+k]\n",
    "        \n",
    "        # Append the following base to the string associated with the k-mer\n",
    "        if k_mer in context_dict:\n",
    "            context_dict[k_mer] += following_base\n",
    "        else:\n",
    "            context_dict[k_mer] = following_base\n",
    "    \n",
    "    return context_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATCTAG\"\n",
    "    d = context_list(s, k)\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The idea behind this solution is to provide insights into the local sequential context of k-mers within a larger sequence, which can help in understanding sequence structure, predicting subsequent bases in a sequence, or identifying common or rare transitions between nucleotides in genomic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. With the above solution, write function ```context_probabilities``` to count the frequencies of symbols in each context and convert these frequencies into probabilities. Run `context_probabilities` with $T=$ `ATGATATCATCGACGATGTAG` and $k$ values 0 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.218964Z",
     "start_time": "2019-07-08T22:04:23.213773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context probabilities for k=0: {'': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}}\n",
      "Context probabilities for k=2: {'AT': {'A': 0.2, 'C': 0.4, 'G': 0.4, 'T': 0.0}, 'TG': {'A': 0.5, 'C': 0.0, 'G': 0.0, 'T': 0.5}, 'GA': {'A': 0.0, 'C': 0.3333333333333333, 'G': 0.0, 'T': 0.6666666666666666}, 'TA': {'A': 0.0, 'C': 0.0, 'G': 0.5, 'T': 0.5}, 'TC': {'A': 0.5, 'C': 0.0, 'G': 0.5, 'T': 0.0}, 'CA': {'A': 0.0, 'C': 0.0, 'G': 0.0, 'T': 1.0}, 'CG': {'A': 1.0, 'C': 0.0, 'G': 0.0, 'T': 0.0}, 'AC': {'A': 0.0, 'C': 0.0, 'G': 1.0, 'T': 0.0}, 'GT': {'A': 1.0, 'C': 0.0, 'G': 0.0, 'T': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "def context_probabilities(s, k):\n",
    "    context_dict = context_list(s, k)\n",
    "    probabilities_dict = {}\n",
    "\n",
    "    for k_mer, following_bases in context_dict.items():\n",
    "        # Initialize the count dictionary for each nucleotide\n",
    "        base_counts = {'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
    "        \n",
    "        # Count the occurrences of each nucleotide in the following bases\n",
    "        for base in following_bases:\n",
    "            if base in base_counts:  # Increment the count for the nucleotide\n",
    "                base_counts[base] += 1\n",
    "        \n",
    "        # Calculate the probability for each nucleotide\n",
    "        total_bases = len(following_bases)\n",
    "        base_probabilities = {base: count / total_bases for base, count in base_counts.items() if total_bases > 0}\n",
    "        \n",
    "        probabilities_dict[k_mer] = base_probabilities\n",
    "    \n",
    "    return probabilities_dict\n",
    "\n",
    "def context_list(s, k):\n",
    "    context_dict = {}\n",
    "    \n",
    "    # Special case for k=0, consider the whole sequence as a single context\n",
    "    if k == 0:\n",
    "        return {'': {base: s.count(base) / len(s) for base in 'ACGT'}}\n",
    "    \n",
    "    # Iterate over the sequence until the second to last k-mer\n",
    "    for i in range(len(s) - k):\n",
    "        k_mer = s[i:i+k]\n",
    "        following_base = s[i+k]\n",
    "        \n",
    "        # Append the following base to the string associated with the k-mer\n",
    "        if k_mer in context_dict:\n",
    "            context_dict[k_mer] += following_base\n",
    "        else:\n",
    "            context_dict[k_mer] = following_base\n",
    "    \n",
    "    return context_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k_values = [0, 2]\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    for k in k_values:\n",
    "        d = context_probabilities(s, k)\n",
    "        print(f\"Context probabilities for k={k}: {d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Idea of this solution is to provide a detailed probabilistic model of nucleotide succession in a DNA sequence, capturing the essence of sequence context dependency in genetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. With the above solution and the function ```random_event``` from the earlier exercise, write class ```MarkovChain```. Its ```generate``` method should generate a random DNA sequence following the original $k$-th order Markov chain probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.279315Z",
     "start_time": "2019-07-08T22:04:23.253983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGTAGTATCG\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class MarkovChain:\n",
    "    \n",
    "    def __init__(self, zeroth, kth, k=2):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "    \n",
    "    def random_event(self, probabilities):\n",
    "        r = random.random()\n",
    "        cumulative_probability = 0.0\n",
    "        for event, event_prob in probabilities.items():\n",
    "            cumulative_probability += event_prob\n",
    "            if r < cumulative_probability:\n",
    "                return event\n",
    "        return event  # Return the last event if no other event is selected\n",
    "\n",
    "    def generate(self, n, seed=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        \n",
    "        # Start by generating the first k nucleotides based on the zeroth order probabilities\n",
    "        sequence = ''.join(self.random_event(self.zeroth) for _ in range(self.k))\n",
    "        \n",
    "        # Then generate the rest of the sequence based on kth order probabilities\n",
    "        for _ in range(n - self.k):\n",
    "            context = sequence[-self.k:]\n",
    "            next_nucleotide_probs = self.kth.get(context, self.zeroth)  # Fallback to zeroth if context not found\n",
    "            next_nucleotide = self.random_event(next_nucleotide_probs)\n",
    "            sequence += next_nucleotide\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    zeroth = {'A': 0.2, 'C': 0.19, 'T': 0.31, 'G': 0.3}\n",
    "    kth = {\n",
    "        'GT': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0},\n",
    "        'CA': {'A': 0.0, 'C': 0.0, 'T': 1.0, 'G': 0.0},\n",
    "        'TC': {'A': 0.5, 'C': 0.0, 'T': 0.0, 'G': 0.5},\n",
    "        'GA': {'A': 0.0, 'C': 0.333, 'T': 0.667, 'G': 0.0},\n",
    "        'TG': {'A': 0.5, 'C': 0.0, 'T': 0.5, 'G': 0.0},\n",
    "        'AT': {'A': 0.2, 'C': 0.4, 'T': 0.0, 'G': 0.4},\n",
    "        'TA': {'A': 0.0, 'C': 0.0, 'T': 0.5, 'G': 0.5},\n",
    "        'AC': {'A': 0.0, 'C': 0.0, 'T': 0.0, 'G': 1.0},\n",
    "        'CG': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0}\n",
    "    }\n",
    "    n = 10    \n",
    "    seed = 0\n",
    "    mc = MarkovChain(zeroth, kth)\n",
    "    print(mc.generate(n, seed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Idea of this solution is to model the DNA sequence generation process where the choice of each nucleotide can depend on a fixed number of preceding nucleotides, reflecting the probabilistic nature of genetic sequences. Such a model can be useful in simulations, bioinformatics analyses, or in understanding the underlying mechanisms of sequence generation in biological systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have survived so far without problems, please run your program a few more times with different inputs. At some point you should get a lookup error in your hash-table! The reason for this is not your code, but the way we defined the model: Some $k$-mers may not be among the training data (input sequence $T$), but such can be generated as the first $k$-mer that is generated using the zero-order model.  \n",
    "\n",
    "A general approach to fixing such issues with incomplete training data is to use *pseudo counts*. That is, all imaginable events are initialized to frequency count 1.   \n",
    "\n",
    "13. Write a new solution `context_pseudo_probabilities` based on the solution to problem 11. But this time use pseudo counts in order to obtain a $k$-th order Markov chain that can assign a probability for any DNA sequence. You may use the standard library function `itertools.product` to iterate over all $k$-mer of given length (`product(\"ACGT\", repeat=k)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.303566Z",
     "start_time": "2019-07-08T22:04:23.296028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroth: {'A': 0.32, 'C': 0.16, 'G': 0.24, 'T': 0.28}\n",
      "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
      "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
      "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
      "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
      "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
      "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
      "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
      "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
      "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
      "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "\n",
      "Generated sequence: GATGATTTTCGTGCAGGTTC\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "def context_pseudo_probabilities(s, k):\n",
    "    # Handle the zeroth order separately\n",
    "    if k == 0:\n",
    "        base_counts = {base: 1 for base in 'ACGT'}  # Start with pseudo counts\n",
    "        for base in s:\n",
    "            base_counts[base] += 1\n",
    "        total = sum(base_counts.values())\n",
    "        return {'': {base: count / total for base, count in base_counts.items()}}\n",
    "    \n",
    "    # Handle kth order\n",
    "    context_dict = {\"\".join(ctx): {nuc: 1 for nuc in 'ACGT'} for ctx in product('ACGT', repeat=k)}  # Pseudo counts\n",
    "    for i in range(len(s) - k):\n",
    "        context = s[i:i+k]\n",
    "        following_nuc = s[i+k]\n",
    "        context_dict[context][following_nuc] += 1\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    for context, counts in context_dict.items():\n",
    "        total = sum(counts.values())\n",
    "        context_dict[context] = {nuc: count / total for nuc, count in counts.items()}\n",
    "\n",
    "    return context_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    zeroth = context_pseudo_probabilities(s, 0)['']\n",
    "    kth = context_pseudo_probabilities(s, k)\n",
    "    print(f\"zeroth: {zeroth}\")\n",
    "    for ctx, probs in kth.items():\n",
    "        print(f\"{ctx}: {probs}\")\n",
    "\n",
    "    mc = MarkovChain(zeroth, kth, k)\n",
    "    print(\"\\nGenerated sequence:\", mc.generate(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Idea behind this solution is to build a probabilistic model that accurately reflects the nucleotide distribution and dependencies in a given sequence, using pseudo-counts to ensure that the model is robust to unseen contexts or nucleotides. This model can then be used to generate new sequences or to assess the likelihood of observed sequences, providing valuable insights into the underlying genetic patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Write class ```MarkovProb``` that given the $k$-th order Markov chain developed above to the constructor, its method ```probability``` computes the probability of a given input DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.346222Z",
     "start_time": "2019-07-08T22:04:23.330779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sequence ATGATATCATCGACGATGTAG is 2.831270190340017e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22559/3421395266.py:33: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  print(f\"Probability of sequence {test_seq} is {mc_prob.probability(test_seq)}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MarkovProb:\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def probability(self, s):\n",
    "        if len(s) < self.k:\n",
    "            return 0.0  # The sequence is too short to apply the k-th order model\n",
    "        \n",
    "        # Initialize the probability with the zeroth-order model for the first k nucleotides\n",
    "        prob = np.product([self.zeroth[nuc] for nuc in s[:self.k]])\n",
    "        \n",
    "        # Multiply by the conditional probabilities for each subsequent nucleotide\n",
    "        for i in range(len(s) - self.k):\n",
    "            context = s[i:i+self.k]\n",
    "            next_nuc = s[i+self.k]\n",
    "            # Use kth order probabilities if context is found, otherwise treat as a rare event (very low probability)\n",
    "            context_prob = self.kth.get(context, {next_nuc: 1 / (sum(self.zeroth.values()) * len(self.zeroth))})\n",
    "            prob *= context_prob.get(next_nuc, 1 / (sum(self.zeroth.values()) * len(self.zeroth)))  # Handle rare event\n",
    "        \n",
    "        return prob\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    kth = context_pseudo_probabilities(s, k)\n",
    "    zeroth = context_pseudo_probabilities(s, 0)[\"\"]\n",
    "    mc_prob = MarkovProb(k, zeroth, kth)\n",
    "    test_seq = \"ATGATATCATCGACGATGTAG\"\n",
    "    print(f\"Probability of sequence {test_seq} is {mc_prob.probability(test_seq)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The idea of this solution is to provide a quantifiable measure of how likely a sequence is, given a Markov model of nucleotide sequences. This can be particularly useful in bioinformatics for sequence analysis, alignment, modeling genetic sequences' behaviors, and understanding the statistical properties of genetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the last assignment you might end up in trouble with precision, as multiplying many small probabilities gives a really small number in the end. There is an easy fix by using so-called log-transform. \n",
    "Consider computation of $P=s_1 s_2 \\cdots s_n$, where $0\\leq s_i\\leq 1$ for each $i$. Taking logarithm in base 2 from both sides gives $\\log _2 P= \\log _2 (s_1 s_2 \\cdots s_n)=\\log_2 s_1 + \\log_2 s_2 + \\cdots \\log s_n= \\sum_{i=1}^n \\log s_i$, with repeated application of the property that the logarithm of a multiplication of two numbers is the sum of logarithms of the two numbers taken separately. The results is abbreviated as log-probability.\n",
    "\n",
    "15. Write class ```MarkovLog``` that given the $k$-th order Markov chain developed above to the constructor, its method ```log_probability``` computes the log-probability of a given input DNA sequence. Run your program with $T=$ `ATGATATCATCGACGATGTAG` and $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.390453Z",
     "start_time": "2019-07-08T22:04:23.379760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of sequence ATGATATCATCGACGATGTAG is -21.985125488470754\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MarkovLog(object):\n",
    "\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "\n",
    "    def log_probability(self, s):\n",
    "        if len(s) < self.k:\n",
    "            return np.log(0)  # Log(0) for sequences shorter than k\n",
    "        \n",
    "        # Compute the log-probability for the first k nucleotides using the zeroth order model\n",
    "        log_prob = np.sum([np.log(self.zeroth[nuc]) for nuc in s[:self.k]])\n",
    "        \n",
    "        # Add the log of conditional probabilities for each subsequent nucleotide\n",
    "        for i in range(len(s) - self.k):\n",
    "            context = s[i:i+self.k]\n",
    "            next_nuc = s[i+self.k]\n",
    "            context_prob = self.kth.get(context, {next_nuc: 1 / (sum(self.zeroth.values()) * len(self.zeroth))})\n",
    "            log_prob += np.log(context_prob.get(next_nuc, 1 / (sum(self.zeroth.values()) * len(self.zeroth))))\n",
    "        \n",
    "        return log_prob\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    kth = context_pseudo_probabilities(s, k)\n",
    "    zeroth = context_pseudo_probabilities(s, 0)[\"\"]\n",
    "    mc_log = MarkovLog(k, zeroth, kth)\n",
    "    test_seq = \"ATGATATCATCGACGATGTAG\"\n",
    "    print(f\"Log probability of sequence {test_seq} is {mc_log.log_probability(test_seq)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "MarkovLog solution is to compute the log-probability of observing a specific DNA sequence under a given k-th order Markov chain model. This approach offers several computational and numerical advantages over directly calculating the sequence's probability, especially for long sequences or when dealing with very small probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you try to use the code so far for very large inputs, you might observe that the concatenation of symbols following a context occupy considerable amount of space. This is unnecessary, as we only need the frequencies. \n",
    "\n",
    "16. Optimize the space requirement of your code from exercise 13 for the $k$-th order Markov chain by replacing the concatenations by direct computations of the frequencies. Implement this as the\n",
    "  ```better_context_probabilities``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.422302Z",
     "start_time": "2019-07-08T22:04:23.416330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
      "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
      "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
      "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
      "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
      "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
      "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
      "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
      "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
      "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "def better_context_probabilities(s, k):\n",
    "    # Initialize context dictionary with pseudo counts to handle unseen k-mers\n",
    "    context_dict = {\n",
    "        ''.join(ctx): {nuc: 1 for nuc in 'ACGT'} for ctx in product('ACGT', repeat=k)\n",
    "    }\n",
    "\n",
    "    # Count occurrences directly without concatenation\n",
    "    for i in range(len(s) - k):\n",
    "        context = s[i:i+k]\n",
    "        next_nuc = s[i+k]\n",
    "        if context in context_dict:\n",
    "            context_dict[context][next_nuc] += 1\n",
    "        else:\n",
    "            # Initialize with pseudo counts if the context is somehow not in the dictionary (shouldn't happen with pseudo counts initialization)\n",
    "            context_dict[context] = {nuc: 1 for nuc in 'ACGT'}\n",
    "            context_dict[context][next_nuc] += 1\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    for context, counts in context_dict.items():\n",
    "        total = sum(counts.values())\n",
    "        context_dict[context] = {nuc: count / total for nuc, count in counts.items()}\n",
    "\n",
    "    return context_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    d = better_context_probabilities(s, k)\n",
    "    for context, probabilities in d.items():\n",
    "        print(f\"{context}: {probabilities}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Idea behind the better_context_probabilities function is to efficiently calculate the probabilities of each nucleotide following a particular sequence (context) of k nucleotides in a given DNA sequence. This function is designed to be space-efficient, avoiding the need to store large amounts of intermediate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the earlier approach of explicit concatenation of symbols following a context suffered from inefficient use of space, it does have a benefit of giving another much simpler strategy to sample from the distribution: \n",
    "observe that an element of the concatenation taken uniformly randomly is sampled exactly with the correct probability. \n",
    "\n",
    "17. Revisit the solution 12 and modify it to directly sample from the concatenation of symbols following a context. The function ```np.random.choice``` may be convenient here. Implement the modified version as the new `SimpleMarkovChain` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.462556Z",
     "start_time": "2019-07-08T22:04:23.453101Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATGTATCGA\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class SimpleMarkovChain(object):\n",
    "    def __init__(self, s, k):\n",
    "        self.k = k\n",
    "        self.contexts = defaultdict(list)\n",
    "        # Build the context list\n",
    "        for i in range(len(s) - k):\n",
    "            self.contexts[s[i:i+k]].append(s[i+k])\n",
    "\n",
    "    def generate(self, n, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "        # Start by choosing a random k-mer as the initial context\n",
    "        initial_context = random.choice(list(self.contexts.keys()))\n",
    "        sequence = initial_context\n",
    "\n",
    "        for _ in range(n - self.k):\n",
    "            context = sequence[-self.k:]\n",
    "            # If the context is not found (which shouldn't happen with our training data), choose a random context\n",
    "            if context not in self.contexts or not self.contexts[context]:\n",
    "                context = random.choice(list(self.contexts.keys()))\n",
    "\n",
    "            # Sample the next nucleotide from the list of observed nucleotides following the current context\n",
    "            next_nucleotide = np.random.choice(self.contexts[context])\n",
    "            sequence += next_nucleotide\n",
    "\n",
    "        return sequence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    n = 10\n",
    "    seed = 7\n",
    "    mc = SimpleMarkovChain(s, k)\n",
    "    print(mc.generate(n, seed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The SimpleMarkovChain class is designed to mimic how DNA sequences naturally evolve, using patterns found in a given sample sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-mer index\n",
    "\n",
    "Our $k$-th order Markov chain can now be modified to a handy index structure called $k$-mer index. This index structure associates to each $k$-mer its list of occurrence positions in DNA sequence $T$.  Given a query $k$-mer $W$, one can thus easily list all positions $i$ with  $T[i..k-1]=W$.\n",
    "\n",
    "18. Implement function ```kmer_index``` inspired by your earlier code for the $k$-th order Markov chain. Test your program with `ATGATATCATCGACGATGTAG` and $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.504405Z",
     "start_time": "2019-07-08T22:04:23.494537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using string:\n",
      "ATGATATCATCGACGATGTAG\n",
      "012345678901234567890\n",
      "\n",
      "2-mer index is:\n",
      "AT: [0, 3, 5, 8, 15]\n",
      "TG: [1, 16]\n",
      "GA: [2, 11, 14]\n",
      "TA: [4, 18]\n",
      "TC: [6, 9]\n",
      "CA: [7]\n",
      "CG: [10, 13]\n",
      "AC: [12]\n",
      "GT: [17]\n",
      "AG: [19]\n"
     ]
    }
   ],
   "source": [
    "def kmer_index(s, k):\n",
    "    index = {}\n",
    "    # Iterate over the sequence to extract k-mers and their positions\n",
    "    for i in range(len(s) - k + 1):\n",
    "        kmer = s[i:i+k]\n",
    "        if kmer in index:\n",
    "            index[kmer].append(i)\n",
    "        else:\n",
    "            index[kmer] = [i]\n",
    "    return index\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    print(\"Using string:\")\n",
    "    print(s)\n",
    "    print(\"\".join([str(i % 10) for i in range(len(s))]))\n",
    "    \n",
    "    print(f\"\\n{k}-mer index is:\")\n",
    "    d = kmer_index(s, k)\n",
    "    for kmer, positions in d.items():\n",
    "        print(f\"{kmer}: {positions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The idea behind the kmer_index solution is to create a quick-reference guide or \"index\" for each short sequence (k-mer) within a longer DNA sequence. This index helps you rapidly find where each k-mer occurs in the DNA sequence, much like an index in a book that helps you find information quickly without reading the entire book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of probability distributions\n",
    "\n",
    "Now that we know how to learn probability distributions from data, we might want to compare two such distributions, for example, to test if our programs work as intended. \n",
    "\n",
    "Let $P=\\{p_1,p_2,\\ldots, p_n\\}$ and $Q=\\{q_1,q_2,\\ldots, q_n\\}$ be two probability distributions for the same set of $n$ events. This means $\\sum_{i=1}^n p_i=\\sum_{i=1}^n q_i=1$, $0\\leq p_j \\leq 1$, and $0\\leq q_j \\leq 1$ for each event $j$. \n",
    "\n",
    "*Kullback-Leibler divergence* is a measure $d()$ for the *relative entropy* of $P$ with respect to $Q$ defined as \n",
    "$d(P||Q)=\\sum_{i=1}^n p_i \\log\\frac{p_i}{q_i}$.\n",
    "\n",
    "\n",
    "This measure is always non-negative, and 0 only when $P=Q$. It can be interpreted as the gain of knowing $Q$ to encode $P$. Note that this measure is not symmetric.\n",
    "\n",
    "19. Write function ```kullback_leibler``` to compute $d(P||Q)$. Test your solution by generating a random RNA sequence\n",
    "  encoding the input protein sequence according to the input codon adaptation probabilities.\n",
    "  Then you should learn the codon adaptation probabilities from the RNA sequence you generated.\n",
    "  Then try the same with uniformly random RNA sequences (which don't have to encode any\n",
    "  specific protein sequence). Compute the relative entropies between the\n",
    "  three distribution (original, predicted, uniform) and you should observe a clear difference.\n",
    "  Because $d(P||Q)$ is not symmetric, you can either print both $d(P||Q)$ and $d(Q||P)$,\n",
    "  or their average.\n",
    "  \n",
    "  This problem may be fairly tricky. Only the `kullback_leibler` function is automatically tested. The codon probabilities is probably a useful helper function. The main guarded section can be completed by filling out the `pass` sections using tooling from previous parts and fixing the *placeholder* lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.557340Z",
     "start_time": "2019-07-08T22:04:23.539188Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (784837457.py, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 40\u001b[0;36m\u001b[0m\n\u001b[0;31m    # ...\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def codon_probabilities(rna):\n",
    "    \"\"\"\n",
    "    Given an RNA sequence, simply calculates the proability of\n",
    "    all 3-mers empirically based on the sequence\n",
    "    \"\"\"\n",
    "    return {\"\".join(codon): 0 for codon in product(\"ACGU\", repeat=3)}\n",
    "    \n",
    "def kullback_leibler(p, q):\n",
    "    \"\"\"\n",
    "    Computes Kullback-Leibler divergence between two distributions.\n",
    "    Both p and q must be dictionaries from events to probabilities.\n",
    "    The divergence is defined only when q[event] == 0 implies p[event] == 0.\n",
    "    \"\"\"\n",
    "    return np.nan\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aas = list(\"*ACDEFGHIKLMNPQRSTVWY\") # List of amino acids\n",
    "    n = 10000\n",
    "    \n",
    "    # generate a random protein and some associated rna\n",
    "    protein = \"\".join(choice(aas, n))    \n",
    "    pass\n",
    "    \n",
    "    # Maybe check that converting back to protein results in the same sequence\n",
    "    pass\n",
    "    \n",
    "    # Calculate codon probabilities of the rna sequence\n",
    "    cp_predicted = codon_probabilities(\"<rna sequence>\") # placeholder call\n",
    "    \n",
    "    # Calculate codon probabilities based on the codon usage table\n",
    "    cp_orig = {\"\".join(codon): 0 for codon in product(\"ACGU\", repeat=3)} # placeholder dict\n",
    "    \n",
    "    # Create a completely random RNA sequence and get the codon probabilities\n",
    "    pass\n",
    "    cp_uniform = codon_probabilities(\"<random rna sequence>\") # placeholder call\n",
    "    \n",
    "    print(\"d(original || predicted) =\", kullback_leibler(cp_orig, cp_predicted))\n",
    "    print(\"d(predicted || original) =\", kullback_leibler(cp_predicted, cp_orig))\n",
    "    print()\n",
    "    print(\"d(original || uniform) =\", kullback_leibler(cp_orig, cp_uniform))\n",
    "    print(\"d(uniform || original) =\", kullback_leibler(cp_uniform, cp_orig))\n",
    "    print()\n",
    "    print(\"d(predicted || uniform) =\", kullback_leibler(cp_predicted, cp_uniform))\n",
    "    print(\"d(uniform || predicted) =\", kullback_leibler(cp_uniform, cp_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary and equilibrium distributions (extra)\n",
    "\n",
    "Let us consider a Markov chain of order one on the set of nucleotides.\n",
    "Its transition probabilities can be expressed as a $4 \\times 4$ matrix\n",
    "$P=(p_{ij})$, where the element $p_{ij}$ gives the probability of the $j$th nucleotide\n",
    "on the condition the previous nucleotide was the $i$th. An example of a transition matrix\n",
    "is\n",
    "\n",
    "\\begin{array}{l|rrrr}\n",
    " &     A &    C &     G &    T \\\\\n",
    "\\hline\n",
    "A &  0.30 &  0.0 &  0.70 &  0.0 \\\\\n",
    "C &  0.00 &  0.4 &  0.00 &  0.6 \\\\\n",
    "G &  0.35 &  0.0 &  0.65 &  0.0 \\\\\n",
    "T &  0.00 &  0.2 &  0.00 &  0.8 \\\\\n",
    "\\end{array}.\n",
    "\n",
    "A distribution $\\pi=(\\pi_1,\\pi_2,\\pi_3,\\pi_4)$ is called *stationary*, if\n",
    "$\\pi = \\pi P$ (the product here is matrix product).\n",
    "\n",
    "20. Write function ```get_stationary_distributions``` that gets a transition matrix as parameter,\n",
    "  and returns the list of stationary distributions. You can do this with NumPy by\n",
    "  first taking transposition of both sides of the above equation to get equation\n",
    "  $\\pi^T = P^T \\pi^T$. Using numpy.linalg.eig take all eigenvectors related to\n",
    "  eigenvalue 1.0. By normalizing these vectors to sum up to one get the stationary distributions\n",
    "  of the original transition matrix. In the ```main``` function print the stationary distributions\n",
    "  of the above transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.591644Z",
     "start_time": "2019-07-08T22:04:23.580588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+0.333, +0.000, +0.667, +0.000\n",
      "-0.000, +0.250, -0.000, +0.750\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_stationary_distributions(transition):\n",
    "    \"\"\"\n",
    "    The function gets a transition matrix of a degree one Markov chain as parameter.\n",
    "    It returns a list of stationary distributions, in vector form, for that chain.\n",
    "    \"\"\"\n",
    "    # Find eigenvalues and eigenvectors of the transposed transition matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(transition.T)\n",
    "    \n",
    "    # Filter eigenvectors corresponding to eigenvalue 1 (or very close to it due to floating-point precision)\n",
    "    stationary = [vec / np.sum(vec) for vec, val in zip(eigenvectors.T, eigenvalues) if np.isclose(val, 1.0)]\n",
    "    \n",
    "    # Ensure that each vector sums to one (normalization)\n",
    "    return [vec.real for vec in stationary]  # Convert to real in case of complex numbers due to computation\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    transition = np.array([[0.3, 0, 0.7, 0],\n",
    "                           [0, 0.4, 0, 0.6],\n",
    "                           [0.35, 0, 0.65, 0],\n",
    "                           [0, 0.2, 0, 0.8]])\n",
    "    stationary_distributions = get_stationary_distributions(transition)\n",
    "    print(\"\\n\".join(\", \".join(f\"{pv:+.3f}\" for pv in p) for p in stationary_distributions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Implement the `kl_divergence` function below so that the main guarded code runs properly. Using your modified Markov chain generator generate a nucleotide sequence $s$ of length $10\\;000$. Choose prefixes of $s$ of lengths $1, 10, 100, 1000$, and $10\\;000$. For each of these prefixes find out their nucleotide distribution (of order 0) using your earlier tool. Use 1 as the pseudo count. Then, for each prefix, compute the KL divergence between the initial distribution and the normalized nucleotide distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.635060Z",
     "start_time": "2019-07-08T22:04:23.618890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probabilities are:\n",
      "[[0.3  0.   0.7  0.  ]\n",
      " [0.   0.4  0.   0.6 ]\n",
      " [0.35 0.   0.65 0.  ]\n",
      " [0.   0.2  0.   0.8 ]]\n",
      "Stationary distributions:\n",
      "[[ 0.33333333  0.          0.66666667  0.        ]\n",
      " [-0.          0.25       -0.          0.75      ]]\n",
      "Using [0.33, 0.00, 0.67, 0.00] as initial distribution\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22559/832333814.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(p * np.log(p / q), where=(p != 0))\n",
      "/tmp/ipykernel_22559/832333814.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.sum(p * np.log(p / q), where=(p != 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL divergence of stationary distribution prefix of length     1 is 0.51082562\n",
      "KL divergence of stationary distribution prefix of length    10 is 0.21078369\n",
      "KL divergence of stationary distribution prefix of length   100 is 0.02303352\n",
      "KL divergence of stationary distribution prefix of length  1000 is 0.00217722\n",
      "KL divergence of stationary distribution prefix of length 10000 is 0.00020645\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Calculate the KL divergence between two distributions.\n",
    "    Ensure that p and q are numpy arrays.\n",
    "    \"\"\"\n",
    "    return np.sum(p * np.log(p / q), where=(p != 0))\n",
    "\n",
    "def empirical_distribution(sequence, pseudo_count=1):\n",
    "    \"\"\"\n",
    "    Calculate the empirical distribution of nucleotides in the sequence.\n",
    "    Add pseudo_count to each nucleotide count for smoothing.\n",
    "    \"\"\"\n",
    "    counts = np.array([sequence.count(nuc) for nuc in 'ACGT']) + pseudo_count\n",
    "    return counts / counts.sum()\n",
    "\n",
    "def generate_sequence(initial, transition, length):\n",
    "    \"\"\"\n",
    "    Generate a sequence of given length using the initial distribution and transition matrix.\n",
    "    \"\"\"\n",
    "    sequence = ''\n",
    "    current_state = np.random.choice(['A', 'C', 'G', 'T'], p=initial)\n",
    "    sequence += current_state\n",
    "\n",
    "    for _ in range(1, length):\n",
    "        next_state = np.random.choice(['A', 'C', 'G', 'T'], p=transition['ACGT'.index(current_state)])\n",
    "        sequence += next_state\n",
    "        current_state = next_state\n",
    "\n",
    "    return sequence\n",
    "\n",
    "def kl_divergences(initial, transition):\n",
    "    lengths = [1, 10, 100, 1000, 10000]\n",
    "    divergences = []\n",
    "\n",
    "    for length in lengths:\n",
    "        sequence = generate_sequence(initial, transition, length)\n",
    "        empirical_dist = empirical_distribution(sequence)\n",
    "        divergence = kl_divergence(initial, empirical_dist)\n",
    "        divergences.append((length, divergence))\n",
    "\n",
    "    return divergences\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    transition = np.array([[0.3, 0, 0.7, 0],\n",
    "                           [0, 0.4, 0, 0.6],\n",
    "                           [0.35, 0, 0.65, 0],\n",
    "                           [0, 0.2, 0, 0.8]])\n",
    "    print(\"Transition probabilities are:\")\n",
    "    print(transition)\n",
    "    stationary_distributions = get_stationary_distributions(transition)\n",
    "    print(\"Stationary distributions:\")\n",
    "    print(np.stack(stationary_distributions))\n",
    "    initial = stationary_distributions[0]  # Assuming the first one is what we want to use\n",
    "    print(\"Using [{}] as initial distribution\\n\".format(\", \".join(f\"{v:.2f}\" for v in initial)))\n",
    "    results = kl_divergences(initial, transition)\n",
    "    for prefix_length, divergence in results:\n",
    "        print(\"KL divergence of stationary distribution prefix \" \\\n",
    "              \"of length {:5d} is {:.8f}\".format(prefix_length, divergence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Implement the following in the ```main``` function.\n",
    "Find the stationary distribution for the following transition matrix:  \n",
    "\n",
    "\\begin{array}{ l | r r r r}\n",
    " & A &     C &     G &     T \\\\\n",
    "\\hline\n",
    "A &  0.30 &  0.10 &  0.50 &  0.10 \\\\\n",
    "C &  0.20 &  0.30 &  0.15 &  0.35 \\\\\n",
    "G &  0.25 &  0.15 &  0.20 &  0.40 \\\\\n",
    "T &  0.35 &  0.20 &  0.40 &  0.05 \\\\\n",
    "\\end{array}\n",
    "\n",
    "Since there is only one stationary distribution, it is called the *equilibrium distribution*.\n",
    "Choose randomly two nucleotide distributions. You can take these from your sleeve or\n",
    "sample them from the Dirichlet distribution. Then for each of these distributions\n",
    "as the initial distribution of the Markov chain, repeat the above experiment.\n",
    "\n",
    "The `main` function should return tuples, where the first element is the (random) initial distribution and the second element contains the results as a list of tuples where the first element is the kl divergence and the second element the empirical nucleotide distribution, for the different prefix lengths.\n",
    "\n",
    "The state distribution should converge to the equilibrium distribution no matter how we\n",
    "start the Markov chain! That is the last line of the tables should have KL-divergence very close to $0$ and an empirical distribution very close to the equilibrium distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.681300Z",
     "start_time": "2019-07-08T22:04:23.657345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probabilities are:\n",
      "[[0.3  0.1  0.5  0.1 ]\n",
      " [0.2  0.3  0.15 0.35]\n",
      " [0.25 0.15 0.2  0.4 ]\n",
      " [0.35 0.2  0.4  0.05]]\n",
      "Equilibrium distribution:\n",
      "[0.27803345 0.17353238 0.32035021 0.22808396]\n",
      "\n",
      "Using [0.2306959  0.20041794 0.351002   0.21788416] as initial distribution:\n",
      "kl-divergence   empirical distribution\n",
      "0.09298662570   [0.2 0.2 0.2 0.4]\n",
      "0.01959911268   [0.21428571 0.14285714 0.35714286 0.28571429]\n",
      "0.03289168640   [0.17307692 0.20192308 0.33653846 0.28846154]\n",
      "0.00364981923   [0.29282869 0.14243028 0.33366534 0.2310757 ]\n",
      "0.00001820215   [0.27568972 0.17483007 0.32177129 0.22770892]\n",
      "\n",
      "Using [0.03354826 0.33311738 0.300237   0.33309736] as initial distribution:\n",
      "kl-divergence   empirical distribution\n",
      "0.09298662570   [0.2 0.2 0.2 0.4]\n",
      "0.03509184433   [0.35714286 0.21428571 0.21428571 0.21428571]\n",
      "0.01261005760   [0.32692308 0.125      0.33653846 0.21153846]\n",
      "0.00020162134   [0.28486056 0.16733068 0.3187251  0.22908367]\n",
      "0.00013437712   [0.27638944 0.16823271 0.32337065 0.2320072 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def main(transition, equilibrium_distribution):\n",
    "    # Generate two random initial distributions from the Dirichlet distribution\n",
    "    initial_distributions = np.random.dirichlet(alpha=[1, 1, 1, 1], size=2)\n",
    "    \n",
    "    results = []\n",
    "    for initial_distribution in initial_distributions:\n",
    "        # For each initial distribution, generate sequences and compute KL divergences and empirical distributions\n",
    "        kl_divergences_and_distributions = []\n",
    "        for length in [1, 10, 100, 1000, 10000]:\n",
    "            sequence = generate_sequence(initial_distribution, transition, length)\n",
    "            empirical_dist = empirical_distribution(sequence)\n",
    "            kl_divergence_value = kl_divergence(empirical_dist, equilibrium_distribution)\n",
    "            kl_divergences_and_distributions.append((kl_divergence_value, empirical_dist))\n",
    "        results.append((initial_distribution, kl_divergences_and_distributions))\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transition = np.array([[0.3, 0.1, 0.5, 0.1],\n",
    "                           [0.2, 0.3, 0.15, 0.35],\n",
    "                           [0.25, 0.15, 0.2, 0.4],\n",
    "                           [0.35, 0.2, 0.4, 0.05]])\n",
    "    print(\"Transition probabilities are:\", transition, sep=\"\\n\")\n",
    "\n",
    "    stationary_distributions = get_stationary_distributions(transition)\n",
    "    equilibrium_distribution = stationary_distributions[0]\n",
    "    print(\"Equilibrium distribution:\")\n",
    "    print(equilibrium_distribution)\n",
    "\n",
    "    experiment_results = main(transition, equilibrium_distribution)\n",
    "    for initial_distribution, results in experiment_results:\n",
    "        print(\"\\nUsing {} as initial distribution:\".format(initial_distribution))\n",
    "        print(\"kl-divergence   empirical distribution\")\n",
    "        for kl_divergence_value, empirical_dist in results:\n",
    "            print(\"{:.11f}   {}\".format(kl_divergence_value, empirical_dist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The idea behind this solution is to demonstrate and verify a fundamental property of Markov chains: regardless of the initial distribution, the state distribution of a Markov chain will converge to its equilibrium (or stationary) distribution as the chain progresses over many steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "fill in"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "598.85px",
    "left": "1223px",
    "right": "20px",
    "top": "121px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
